# DStudy
Repositório para estudar e organizar Pipelines e projetos de ciência de dados.

## Pipeline
As etapas do Pipeline para realizar o projeto:

1. Definição do problema:
   
Essa etapa envolve compreender claramente o problema e os principais conceitos e abordagens que o cercam.

2. Coleta e Aquisição dos dados: 
Nessa etapa, estabelecemos como iremos coletar ou adquirir os dados. Através do disco local? Drive? Web scraping? De que forma teremos acesso aos dados utilizados.

3. Pré-processamento e Limpeza dos dados:
Aqui, deve-se realizar uma análise exploratória dos dados, buscando identificar possíveis problemas como valores ausentes, ruídos, outliers, entre outros. Em seguida, tratar esses problemas através da limpeza e o pré-processamento, incluindo etapas como preenchimento, tratamento de outliers e normalização.

4. Feature Engineering:
Essa etapa envolve a extração e seleção das características relevantes dos dados. Pode incluir a criação de novas variáveis, transformação de características existentes e redução da dimensionalidade dos dados. 

5. Divisão dos dados:
É a etapa que divide os dados em treinamento, validação e testes.

6. Treinamento e seleção do modelo:
Escolher o algoritmo de aprendizado de máquina mais adequados para o problema e treinar o modelo usando o conjunto de treinamento. É possivel realizar ajustes nos hiperparâmetros do modelo por meio de validação cruzada e técnicas de validação.

7. Ajuste e otimização do modelo

8. Avaliação Final

9. Deploy